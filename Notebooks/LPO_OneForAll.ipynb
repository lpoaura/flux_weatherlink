{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f04abac",
   "metadata": {},
   "source": [
    "# 1 : Librairies Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c98ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 : Librairies et options\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import requests\n",
    "import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import JSON, BigInteger, Integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389abd87",
   "metadata": {},
   "source": [
    "# 2 : Clés API et BDD :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7c465b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informations API : https://weatherlink.github.io/v2-api/\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Clés API :\n",
    "API_key = os.getenv(\"API_key\")\n",
    "API_secret = os.getenv(\"API_secret\")\n",
    "station_ID = os.getenv(\"station_ID\")\n",
    "\n",
    "# Paramètres de connexion à la base de données PostgreSQL en local :\n",
    "host = os.getenv(\"host\")\n",
    "database = os.getenv(\"database\")\n",
    "user = os.getenv(\"user\")\n",
    "password = os.getenv(\"password\")\n",
    "nom_table = os.getenv(\"nom_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efff895",
   "metadata": {},
   "source": [
    "# 3 : Définitions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1deee491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def today_ts():\n",
    "    \"\"\"Récupération de la date du jour à 00h00 en TS pour utilisation comme\n",
    "    date de fin avec l'API.\"\"\"\n",
    "    today = datetime.date.today()\n",
    "    today_midnight = datetime.datetime.combine(today, datetime.time.min)\n",
    "    end_date = int(today_midnight.timestamp())\n",
    "    return end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75590fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_station():\n",
    "    \"\"\"Transformation de la date du début de la station en TS.\"\"\"\n",
    "    start_day = datetime.datetime(2021, 9, 29, 0, 0)\n",
    "    start_day = int(start_day.timestamp())\n",
    "    if_exists = \"replace\"  # informations pour la BDD\n",
    "    return start_day, if_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7309bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_ts_bdd():\n",
    "    \"\"\"Récupération de la dernière TS enregistrée dans la base de données.\"\"\"\n",
    "    # Connexion à la base de données\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=database,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        host=host,\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Exécution d'une requête SQL et récupération de la TS :\n",
    "    cur.execute(f\"SELECT ts FROM {nom_table} ORDER BY ts DESC LIMIT 1\")\n",
    "    data_extract = cur.fetchall()\n",
    "    last_ts = pd.DataFrame(\n",
    "        data_extract, columns=[desc[0] for desc in cur.description]\n",
    "    ).values[0][0]\n",
    "    if_exists = \"append\"  # informations pour la BDD\n",
    "\n",
    "    # Fermeture du curseur et de la connexion\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    return last_ts, if_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4be148bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_api():\n",
    "    \"\"\"Choix de la TS de début à utiliser, en fonction de si la bdd est vide\n",
    "    (historique) ou qu'elle contient déjà des données (routine)\"\"\"\n",
    "\n",
    "    try:  # Présence d'une TS dans la table :\n",
    "        start_date, if_exists = last_ts_bdd()\n",
    "\n",
    "    except psycopg2.ProgrammingError:  # Gérer l'erreur connexion BDD\n",
    "        start_date, if_exists = start_station()\n",
    "\n",
    "    return start_date, if_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d55906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_day_data(start_date_api, end_date_api):\n",
    "    \"\"\"Récupération des données jour/jour via l'API et optention d'une DF.\"\"\"\n",
    "    # DataFrame historiques :\n",
    "    df_ajout = pd.DataFrame()\n",
    "\n",
    "    # Nb de jours à récupérer :\n",
    "    nb_jours = int((end_date_api - start_date_api) / 86400)\n",
    "\n",
    "    for i in tqdm.tqdm(range(nb_jours)):\n",
    "        start_time = start_date_api + i * 86400\n",
    "        end_time = start_time + 86400\n",
    "\n",
    "        # Lien de la request :\n",
    "        link = (\n",
    "            f\"https://api.weatherlink.com/v2/historic/{station_ID}?\" # Base URL\n",
    "            f\"api-key={API_key}&\"  # Clé API\n",
    "            f\"start-timestamp={start_time}&\"  # Timestamp de début\n",
    "            f\"end-timestamp={end_time}\"  # Timestamp de fin\n",
    "        )\n",
    "\n",
    "        headers = {\"X-Api-Secret\": API_secret}\n",
    "\n",
    "        # Requête :\n",
    "        r = requests.get(link, headers=headers, timeout=60)\n",
    "\n",
    "        # Si la requête a réussi :\n",
    "        if r.status_code == 200:\n",
    "            # Lecture de la request en json :\n",
    "            data = r.json()\n",
    "\n",
    "            # Transformation en DF :\n",
    "            df_jour = pd.DataFrame(data)\n",
    "            df_jour = df_jour[[\"station_id\", \"sensors\"]]\n",
    "\n",
    "            # Récupération des valeurs se trouvant dans sensors :\n",
    "            df_sensors = pd.json_normalize(data[\"sensors\"][0][\"data\"])\n",
    "\n",
    "            # Récupération des json sur une colonne :\n",
    "            df_jour = pd.DataFrame(\n",
    "                {\n",
    "                    \"station_id\": data[\"station_id\"],\n",
    "                    \"infos_json\": data[\"sensors\"][0][\"data\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Convertir les objets JSON en chaînes de caractères JSON :\n",
    "            df_jour[\"infos_json\"] = df_jour[\"infos_json\"].apply(json.dumps)\n",
    "\n",
    "            # Concat des données :\n",
    "            df_jour = pd.concat([df_jour, df_sensors], axis=1)\n",
    "\n",
    "            # Concaténation des données :\n",
    "            df_ajout = pd.concat([df_ajout, df_jour], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"La requête {link} a échoué, code erreur : {r.status_code}\")\n",
    "    \n",
    "    return df_ajout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66544d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_to_BDD(df_ajout, if_exists) :\n",
    "    \"\"\"Ajout des données dans la BDD.\"\"\"\n",
    "    # Connexion de la chaîne de connexion PostgreSQL :\n",
    "    conn_str = f\"postgresql://{user}:{password}@{host}/{database}\"\n",
    "    engine = create_engine(conn_str)\n",
    "\n",
    "    # Définir les types de données pour chaque colonne :\n",
    "    dtype = {\"station_id\": Integer(), \"ts\": BigInteger(), \"infos_json\": JSON}\n",
    "\n",
    "    # Insérer le DataFrame dans la base de données PostgreSQL :\n",
    "    df_ajout.to_sql(\n",
    "        nom_table,\n",
    "        engine,\n",
    "        if_exists=if_exists,\n",
    "        index=False,\n",
    "        dtype=dtype,\n",
    "    )\n",
    "\n",
    "    # Fermeture de la connexion :\n",
    "    engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3c3c05",
   "metadata": {},
   "source": [
    "# 4 : Récupération des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b988c4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                  | 1/942 [00:01<19:42,  1.26s/it]C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_5420\\1577343197.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ajout = pd.concat([df_ajout, df_jour], ignore_index=True)\n",
      "  9%|███████                                                                          | 82/942 [02:19<26:51,  1.87s/it]C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_5420\\1577343197.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ajout = pd.concat([df_ajout, df_jour], ignore_index=True)\n",
      " 11%|█████████                                                                       | 106/942 [03:06<32:08,  2.31s/it]C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_5420\\1577343197.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ajout = pd.concat([df_ajout, df_jour], ignore_index=True)\n",
      " 12%|█████████▊                                                                      | 116/942 [03:27<27:53,  2.03s/it]C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_5420\\1577343197.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ajout = pd.concat([df_ajout, df_jour], ignore_index=True)\n",
      " 13%|██████████▏                                                                     | 120/942 [03:35<27:25,  2.00s/it]C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_5420\\1577343197.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ajout = pd.concat([df_ajout, df_jour], ignore_index=True)\n",
      " 46%|█████████████████████████████████████▏                                          | 438/942 [19:42<31:26,  3.74s/it]C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_5420\\1577343197.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ajout = pd.concat([df_ajout, df_jour], ignore_index=True)\n",
      " 47%|█████████████████████████████████████▎                                          | 439/942 [19:46<31:19,  3.74s/it]C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_5420\\1577343197.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ajout = pd.concat([df_ajout, df_jour], ignore_index=True)\n",
      " 47%|█████████████████████████████████████▋                                          | 444/942 [20:04<30:56,  3.73s/it]C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_5420\\1577343197.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ajout = pd.concat([df_ajout, df_jour], ignore_index=True)\n",
      " 51%|████████████████████████████████████████▊                                       | 480/942 [22:25<29:58,  3.89s/it]C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_5420\\1577343197.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ajout = pd.concat([df_ajout, df_jour], ignore_index=True)\n",
      " 88%|██████████████████████████████████████████████████████████████████████▋         | 832/942 [51:57<10:38,  5.80s/it]C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_5420\\1577343197.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ajout = pd.concat([df_ajout, df_jour], ignore_index=True)\n",
      " 89%|██████████████████████████████████████████████████████████████████████▉         | 835/942 [52:16<10:47,  6.05s/it]C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_5420\\1577343197.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ajout = pd.concat([df_ajout, df_jour], ignore_index=True)\n",
      " 89%|██████████████████████████████████████████████████████████████████████▉         | 836/942 [52:22<10:32,  5.97s/it]C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_5420\\1577343197.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ajout = pd.concat([df_ajout, df_jour], ignore_index=True)\n",
      " 89%|███████████████████████████████████████████████████████████████████████▌        | 843/942 [53:02<09:39,  5.85s/it]C:\\Users\\Johan\\AppData\\Local\\Temp\\ipykernel_5420\\1577343197.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ajout = pd.concat([df_ajout, df_jour], ignore_index=True)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 942/942 [1:04:24<00:00,  4.10s/it]\n"
     ]
    }
   ],
   "source": [
    "# Utilisation des définitions pour la récupération des données :\n",
    "start_date_api, if_exists = start_api()\n",
    "end_date_api = today_ts()\n",
    "df_ajout = one_day_data(start_date_api, end_date_api)\n",
    "up_to_BDD(df_ajout, if_exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f694e0",
   "metadata": {},
   "source": [
    "# 5 : Ouverture de la BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d308f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>infos_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>tz_offset</th>\n",
       "      <th>arch_int</th>\n",
       "      <th>rev_type</th>\n",
       "      <th>temp_out</th>\n",
       "      <th>temp_out_hi</th>\n",
       "      <th>temp_out_lo</th>\n",
       "      <th>temp_in</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_run</th>\n",
       "      <th>deg_days_heat</th>\n",
       "      <th>deg_days_cool</th>\n",
       "      <th>solar_energy</th>\n",
       "      <th>uv_dose</th>\n",
       "      <th>thw_index</th>\n",
       "      <th>thsw_index</th>\n",
       "      <th>wet_bulb</th>\n",
       "      <th>night_cloud_cover</th>\n",
       "      <th>iss_reception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122495</td>\n",
       "      <td>{\"ts\": 1632942900, \"tz_offset\": 7200, \"arch_in...</td>\n",
       "      <td>1632942900</td>\n",
       "      <td>7200</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>56.1</td>\n",
       "      <td>56.2</td>\n",
       "      <td>56.1</td>\n",
       "      <td>74.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.680000</td>\n",
       "      <td>52.794106</td>\n",
       "      <td>51.865425</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122495</td>\n",
       "      <td>{\"ts\": 1632943200, \"tz_offset\": 7200, \"arch_in...</td>\n",
       "      <td>1632943200</td>\n",
       "      <td>7200</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>73.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.580000</td>\n",
       "      <td>52.241997</td>\n",
       "      <td>51.771530</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122495</td>\n",
       "      <td>{\"ts\": 1632943500, \"tz_offset\": 7200, \"arch_in...</td>\n",
       "      <td>1632943500</td>\n",
       "      <td>7200</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>56.2</td>\n",
       "      <td>56.2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>71.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.780003</td>\n",
       "      <td>52.441998</td>\n",
       "      <td>51.957924</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122495</td>\n",
       "      <td>{\"ts\": 1632943800, \"tz_offset\": 7200, \"arch_in...</td>\n",
       "      <td>1632943800</td>\n",
       "      <td>7200</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>56.3</td>\n",
       "      <td>56.4</td>\n",
       "      <td>56.2</td>\n",
       "      <td>69.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.880000</td>\n",
       "      <td>52.541996</td>\n",
       "      <td>52.050987</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122495</td>\n",
       "      <td>{\"ts\": 1632944100, \"tz_offset\": 7200, \"arch_in...</td>\n",
       "      <td>1632944100</td>\n",
       "      <td>7200</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>57.7</td>\n",
       "      <td>57.7</td>\n",
       "      <td>56.3</td>\n",
       "      <td>67.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.920002</td>\n",
       "      <td>53.537514</td>\n",
       "      <td>51.984350</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id                                         infos_json          ts  \\\n",
       "0      122495  {\"ts\": 1632942900, \"tz_offset\": 7200, \"arch_in...  1632942900   \n",
       "1      122495  {\"ts\": 1632943200, \"tz_offset\": 7200, \"arch_in...  1632943200   \n",
       "2      122495  {\"ts\": 1632943500, \"tz_offset\": 7200, \"arch_in...  1632943500   \n",
       "3      122495  {\"ts\": 1632943800, \"tz_offset\": 7200, \"arch_in...  1632943800   \n",
       "4      122495  {\"ts\": 1632944100, \"tz_offset\": 7200, \"arch_in...  1632944100   \n",
       "\n",
       "   tz_offset  arch_int  rev_type  temp_out  temp_out_hi  temp_out_lo  temp_in  \\\n",
       "0       7200       300         2      56.1         56.2         56.1     74.6   \n",
       "1       7200       300         2      56.0         56.2         56.0     73.8   \n",
       "2       7200       300         2      56.2         56.2         56.0     71.6   \n",
       "3       7200       300         2      56.3         56.4         56.2     69.3   \n",
       "4       7200       300         2      57.7         57.7         56.3     67.4   \n",
       "\n",
       "   ...  wind_run  deg_days_heat  deg_days_cool  solar_energy  uv_dose  \\\n",
       "0  ...       0.0       0.030903            0.0           0.0      NaN   \n",
       "1  ...       0.0       0.031250            0.0           0.0      NaN   \n",
       "2  ...       0.0       0.030556            0.0           0.0      NaN   \n",
       "3  ...       0.0       0.030208            0.0           0.0      NaN   \n",
       "4  ...       0.0       0.025347            0.0           0.0      0.0   \n",
       "\n",
       "   thw_index  thsw_index   wet_bulb  night_cloud_cover  iss_reception  \n",
       "0  55.680000   52.794106  51.865425                0.5           None  \n",
       "1  55.580000   52.241997  51.771530                0.5           None  \n",
       "2  55.780003   52.441998  51.957924                0.5           None  \n",
       "3  55.880000   52.541996  52.050987                0.5           None  \n",
       "4  56.920002   53.537514  51.984350                0.5           None  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connexion à la base de données\n",
    "conn = psycopg2.connect(dbname = database, user = user, password = password , host = host)\n",
    "\n",
    "# Création d'un curseur : permet d'exécuter des commandes SQL sur la base de données.\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Exécution d'une requête SQL pour sélectionner les données de ma_table\n",
    "cur.execute(f\"SELECT * FROM {nom_table} LIMIT 5\")\n",
    "\n",
    "# Récupération des données dans une liste de tuples\n",
    "data = cur.fetchall()\n",
    "\n",
    "# Création d'un DataFrame à partir des données\n",
    "df = pd.DataFrame(data, columns=[desc[0] for desc in cur.description])\n",
    "\n",
    "# Fermeture du curseur et de la connexion\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c98928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La colonne  et à pour format : double precision\n",
      "La colonne  abs_press à pour format : double precision\n",
      "La colonne  bar_noaa à pour format : double precision\n",
      "La colonne  bar à pour format : double precision\n",
      "La colonne  solar_rad_avg à pour format : double precision\n",
      "La colonne  dew_point_out à pour format : double precision\n",
      "La colonne  dew_point_in à pour format : double precision\n",
      "La colonne  emc à pour format : double precision\n",
      "La colonne  heat_index_out à pour format : double precision\n",
      "La colonne  heat_index_in à pour format : double precision\n",
      "La colonne  wind_chill à pour format : double precision\n",
      "La colonne  wind_run à pour format : double precision\n",
      "La colonne  deg_days_heat à pour format : double precision\n",
      "La colonne  deg_days_cool à pour format : double precision\n",
      "La colonne  solar_energy à pour format : double precision\n",
      "La colonne  uv_dose à pour format : double precision\n",
      "La colonne  thw_index à pour format : double precision\n",
      "La colonne  thsw_index à pour format : double precision\n",
      "La colonne  wet_bulb à pour format : double precision\n",
      "La colonne  night_cloud_cover à pour format : double precision\n",
      "La colonne  station_id à pour format : integer\n",
      "La colonne  solar_rad_hi à pour format : double precision\n",
      "La colonne  uv_index_avg à pour format : double precision\n",
      "La colonne  uv_index_hi à pour format : double precision\n",
      "La colonne  wind_num_samples à pour format : bigint\n",
      "La colonne  wind_speed_avg à pour format : double precision\n",
      "La colonne  wind_speed_hi à pour format : bigint\n",
      "La colonne  wind_dir_of_hi à pour format : double precision\n",
      "La colonne  wind_dir_of_prevail à pour format : double precision\n",
      "La colonne  infos_json à pour format : json\n",
      "La colonne  ts à pour format : bigint\n",
      "La colonne  tz_offset à pour format : bigint\n",
      "La colonne  arch_int à pour format : bigint\n",
      "La colonne  rev_type à pour format : bigint\n",
      "La colonne  temp_out à pour format : double precision\n",
      "La colonne  temp_out_hi à pour format : double precision\n",
      "La colonne  temp_out_lo à pour format : double precision\n",
      "La colonne  temp_in à pour format : double precision\n",
      "La colonne  hum_in à pour format : bigint\n",
      "La colonne  hum_out à pour format : double precision\n",
      "La colonne  rainfall_in à pour format : double precision\n",
      "La colonne  rainfall_clicks à pour format : bigint\n",
      "La colonne  rainfall_mm à pour format : double precision\n",
      "La colonne  rain_rate_hi_in à pour format : double precision\n",
      "La colonne  rain_rate_hi_clicks à pour format : bigint\n",
      "La colonne  rain_rate_hi_mm à pour format : double precision\n",
      "La colonne  forecast_rule à pour format : double precision\n",
      "La colonne  iss_reception à pour format : text\n",
      "La colonne  moist_soil_1 à pour format : text\n",
      "La colonne  moist_soil_2 à pour format : text\n",
      "La colonne  moist_soil_3 à pour format : text\n",
      "La colonne  moist_soil_4 à pour format : text\n",
      "La colonne  temp_soil_1 à pour format : text\n",
      "La colonne  temp_soil_2 à pour format : text\n",
      "La colonne  temp_soil_3 à pour format : text\n",
      "La colonne  temp_soil_4 à pour format : text\n",
      "La colonne  wet_leaf_1 à pour format : text\n",
      "La colonne  wet_leaf_2 à pour format : text\n",
      "La colonne  temp_leaf_1 à pour format : text\n",
      "La colonne  temp_leaf_2 à pour format : text\n",
      "La colonne  temp_extra_1 à pour format : text\n",
      "La colonne  temp_extra_2 à pour format : text\n",
      "La colonne  temp_extra_3 à pour format : text\n",
      "La colonne  hum_extra_1 à pour format : text\n",
      "La colonne  hum_extra_2 à pour format : text\n",
      "La colonne  forecast_desc à pour format : text\n",
      "La colonne  bar_alt à pour format : text\n",
      "La colonne  air_density à pour format : text\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Connexion à la base de données\n",
    "conn = psycopg2.connect(dbname=database, user=user, password=password, host=host)\n",
    "\n",
    "# Création d'un curseur : permet d'exécuter des commandes SQL sur la base de données.\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Exécution d'une requête SQL pour obtenir les informations de schéma de la table\n",
    "cur.execute(\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = 'historiquemeteo'\")\n",
    "\n",
    "# Récupération des données dans une liste de tuples\n",
    "column_info = cur.fetchall()\n",
    "\n",
    "# Affichage du format de chaque colonne\n",
    "for column in column_info:\n",
    "    print(\"La colonne \", column[0], \"à pour format :\", column[1])\n",
    "\n",
    "# Fermeture du curseur et de la connexion\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708372b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lpo-aura-py3.11",
   "language": "python",
   "name": "lpo-aura-py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
